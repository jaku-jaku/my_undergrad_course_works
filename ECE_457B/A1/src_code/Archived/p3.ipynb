{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python typical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from typing import List, Dict, Optional\n",
    "from enum import Enum, IntEnum, auto\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, KFold, cross_val_score\n",
    ")\n",
    "\n",
    "# # tensor flow\n",
    "# import tensorflow.keras as keras\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# python debugger\n",
    "from icecream import ic # Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# one layer model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class P3_Env:\n",
    "    _train_data_x: List[float]\n",
    "    _train_data_y: List[float]\n",
    "    _test_data_x: List[float]\n",
    "    _test_data_y: List[float]\n",
    "\n",
    "    @staticmethod\n",
    "    def print(content: str):\n",
    "        print(\"[ P3_Env ] > {}\".format(content))\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        f_data_function, \n",
    "        x_range: List[float],\n",
    "        # default common configuration\n",
    "        data_pts_i: List[int]       = [100],#[10,40,80,200],\n",
    "        hidden_nodes_j: List[int]   = [100],#[2,10,40,100],\n",
    "        N_eval_per_model: int       = 5, # repeat the process 5 times by shuffling the data generated randomly\n",
    "        MAX_DATA_SIZE: int          = 500,\n",
    "        TRAIN_SIZE: float           = 0.8, # 80 % for training by default\n",
    "    )->None:\n",
    "        self.data_pts_i = data_pts_i\n",
    "        self.hidden_nodes_j = hidden_nodes_j\n",
    "        self.N_eval_per_model = N_eval_per_model\n",
    "        self.MAX_DATA_SIZE = MAX_DATA_SIZE\n",
    "        self.TRAIN_SIZE = TRAIN_SIZE\n",
    "\n",
    "        # generate storage:\n",
    "        self.M_ij_train_errs = np.zeros((len(data_pts_i), len(hidden_nodes_j), N_eval_per_model))\n",
    "        self.M_ij_valid_errs = np.zeros((len(data_pts_i), len(hidden_nodes_j), N_eval_per_model))\n",
    "        self.mlps = {}\n",
    "\n",
    "        # generate test data\n",
    "        data_x = np.arange(x_range[0], x_range[1], (x_range[1]-x_range[0])/MAX_DATA_SIZE)\n",
    "        data_y = f_data_function(data_x)\n",
    "        \n",
    "        self._train_data_x, self._test_data_x, self._train_data_y, self._test_data_y = \\\n",
    "            train_test_split(data_x, data_y, train_size=TRAIN_SIZE, shuffle=True)\n",
    "\n",
    "        # report\n",
    "        self.print(\"Data Size: [ Train: {train} | Test: {test} ]\"\\\n",
    "            .format(train=np.shape(self._train_data_x), test=np.shape(self._test_data_x)))\n",
    "\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        validation_split: float = 0.1, # Default: 10-fold x-validation\n",
    "        N_epoch: int            = 100, # Early stopping\n",
    "        plot: bool              = True\n",
    "    ):\n",
    "        # generate models:\n",
    "        # for n in range(N_eval_per_model):\n",
    "        for i in range(len(self.data_pts_i)):\n",
    "            n_data = self.data_pts_i[i]\n",
    "            \n",
    "            # data selection and shuffle\n",
    "            c = list(zip(self._train_data_x, self._train_data_y))\n",
    "            np.random.shuffle(c)\n",
    "            X,Y = zip(*c)\n",
    "            # down sample\n",
    "            X,Y = X[0:n_data],Y[0:n_data]\n",
    "\n",
    "            # time to train!\n",
    "            for j in range(len(self.hidden_nodes_j)):\n",
    "                n_nodes = self.hidden_nodes_j[j]\n",
    "                mode = \"{itr}_dn={i}_hn={j}\".format(itr=0, i=n_data, j=n_nodes)\n",
    "                self.print(mode)\n",
    "\n",
    "                # define base model:\n",
    "                # mlp = keras.models.Sequential([\n",
    "                #     Dense(n_nodes, activation='sigmoid', input_shape=(1,)),\n",
    "                #     Dense(1, kernel_initializer='normal')\n",
    "                # ])\n",
    "                # mlp.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "                # print(mlp.summary())\n",
    "            \n",
    "                # evaluate model\n",
    "                # estimator = KerasRegressor(build_fn=mlp, epochs=N_epoch, batch_size=5, verbose=0)\n",
    "\n",
    "                # 10-fold\n",
    "                # kfold = KFold(n_splits=10)\n",
    "                # results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "                # self.print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "\n",
    "                # # train\n",
    "                # h = mlp.fit(X, Y, \\\n",
    "                #     epochs=N_epoch, validation_split=0.25, batch_size=32, verbose=0)\n",
    "\n",
    "                # gen report\n",
    "                # if plot:\n",
    "                #     fig1 = plt.gcf()\n",
    "                #     ax1 = plt.subplot(111)\n",
    "                #     plt.plot(h.history['accuracy'])\n",
    "                #     plt.plot(h.history['val_accuracy'], 'r')\n",
    "                #     plt.legend(['train acc', 'val acc'])\n",
    "                #     fig1.savefig(\"fig/p3/train_progress_{}.png\".format(\n",
    "                #         mode\n",
    "                #     ), bbox_inches = 'tight')\n",
    "\n",
    "                # self.print('train acc: %.2f %%'%(h.history['accuracy'][-1]*100))\n",
    "                # self.print('valid acc: %.2f %%'%(h.history['val_accuracy'][-1]*100))\n",
    "\n",
    "                # # store error data\n",
    "                # self.M_ij_train_errs[i][j][0] = h.history['accuracy'][-1]\n",
    "                # self.M_ij_valid_errs[i][j][0] = h.history['val_accuracy'][-1]\n",
    "\n",
    "                # self.mlps[mode] = {\n",
    "                #     \"model\": mlp,\n",
    "                #     \"train_result\": h\n",
    "                # }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ P3_Env ] > Data Size: [ Train: (400,) | Test: (100,) ]\n"
     ]
    }
   ],
   "source": [
    "TEST = P3_Env(\n",
    "    f_data_function = (lambda x: x * np.sin(6 * np.pi * x) * np.exp(- x ** 2)),\n",
    "    x_range = [-1, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ P3_Env ] > 0_dn=100_hn=100\n",
      "[ P3_Env ] > Results: nan (nan) MSE\n"
     ]
    }
   ],
   "source": [
    "TEST.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}